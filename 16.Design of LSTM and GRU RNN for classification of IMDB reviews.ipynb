{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HARI PRASATH S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ko7aKbGjXwgp"
   },
   "source": [
    "# Lab16: Design of LSTM and GRU RNN for classification of IMDB reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9aqx6vkurzX"
   },
   "source": [
    "##### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "V93vdGIHWZaD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd    \n",
    "import numpy as np     \n",
    "from nltk.corpus import stopwords   \n",
    "from sklearn.model_selection import train_test_split       \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   \n",
    "from tensorflow.keras.models import Sequential     \n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   \n",
    "from tensorflow.keras.models import load_model  \n",
    "import re\n",
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "zCReSC0WobP0",
    "outputId": "f400b2bb-eca2-452e-8ca7-56d28ed1f3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOCiZn7Ruvou"
   },
   "source": [
    "##### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "a9waLD4_q335"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "hna1AROTq7zI",
    "outputId": "61ab3d53-9dd2-4b26-fd28-42a1a1c1122f"
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    df = pd.read_csv('IMDB Dataset.csv')\n",
    "    x_data = df['review']       \n",
    "    y_data = df['sentiment']    \n",
    "\n",
    "    \n",
    "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          \n",
    "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
    "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
    "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
    "    \n",
    "    \n",
    "    y_data = y_data.replace('positive', 1)\n",
    "    y_data = y_data.replace('negative', 0)\n",
    "\n",
    "    return x_data, y_data\n",
    "\n",
    "x_data, y_data = load_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWmWLqXOuzAl"
   },
   "source": [
    "##### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "rpYHsaMOrXwK",
    "outputId": "82693008-f3f2-4847-81b8-97999d5e9d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "29955    [it, may, although, still, two, three, i, miss...\n",
      "39093    [i, years, old, i, saw, musical, movie, vacati...\n",
      "48965    [recovery, well, judged, balanced, drama, sens...\n",
      "3170     [anyone, watched, alien, vs, predator, must, k...\n",
      "49564    [they, say, david, duchovny, took, six, days, ...\n",
      "                               ...                        \n",
      "33504    [forget, recent, dire, american, remake, sadly...\n",
      "19565    [oh, wow, i, saw, film, irish, international, ...\n",
      "9631     [what, i, say, this, one, perfect, films, ever...\n",
      "40735    [i, hate, programme, concept, ludicrous, tries...\n",
      "20107    [come, get, pakistan, bashing, guys, bollywood...\n",
      "Name: review, Length: 40000, dtype: object \n",
      "\n",
      "19850    [movies, like, need, sequels, part, advantage,...\n",
      "33276    [too, much, added, much, taken, away, great, w...\n",
      "27090    [friend, made, watch, awful, film, ugh, stupid...\n",
      "37230    [ed, wood, perhaps, worst, film, maker, time, ...\n",
      "27416    [antwone, fisher, tells, young, black, u, s, n...\n",
      "                               ...                        \n",
      "45910    [i, liked, movie, real, lot, wanted, see, dara...\n",
      "32317    [much, said, without, words, this, excellent, ...\n",
      "44685    [seen, many, japanese, horrorfilms, say, reall...\n",
      "3799     [a, hard, find, film, coasts, still, pervasive...\n",
      "25790    [a, really, wonderful, cast, talented, technic...\n",
      "Name: review, Length: 10000, dtype: object \n",
      "\n",
      "Test Set\n",
      "29955    0\n",
      "39093    1\n",
      "48965    1\n",
      "3170     0\n",
      "49564    0\n",
      "        ..\n",
      "33504    1\n",
      "19565    1\n",
      "9631     1\n",
      "40735    0\n",
      "20107    0\n",
      "Name: sentiment, Length: 40000, dtype: int64 \n",
      "\n",
      "19850    0\n",
      "33276    1\n",
      "27090    0\n",
      "37230    0\n",
      "27416    1\n",
      "        ..\n",
      "45910    1\n",
      "32317    1\n",
      "44685    0\n",
      "3799     0\n",
      "25790    0\n",
      "Name: sentiment, Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
    "\n",
    "print('Train Set')\n",
    "print(x_train, '\\n')\n",
    "print(x_test, '\\n')\n",
    "print('Test Set')\n",
    "print(y_train, '\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "c5S3yT6LsssB"
   },
   "outputs": [],
   "source": [
    "def get_max_length():\n",
    "    review_length = []\n",
    "    for review in x_train:\n",
    "        review_length.append(len(review))\n",
    "\n",
    "    return int(np.ceil(np.mean(review_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "IeI8I5jBrhqg",
    "outputId": "c2092caf-18f2-4886-c597-4f0cbbcc1824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[    7   107   167 ...     0     0     0]\n",
      " [    1    71    72 ...  4990 15844    71]\n",
      " [14061    16  6465 ...     0     0     0]\n",
      " ...\n",
      " [  105     1    59 ...     0     0     0]\n",
      " [    1   635  5110 ...     0     0     0]\n",
      " [  122    19  9955 ...     0     0     0]] \n",
      "\n",
      "Encoded X Test\n",
      " [[   28     6   274 ...     0     0     0]\n",
      " [ 1410    17  1148 ...     0     0     0]\n",
      " [  332    24    35 ...     0     0     0]\n",
      " ...\n",
      " [   38    37   845 ...     0     0     0]\n",
      " [   40   154    80 ... 26696  9356   721]\n",
      " [   40    14   300 ...  1650  6766     2]] \n",
      "\n",
      "Maximum review length:  131\n"
     ]
    }
   ],
   "source": [
    "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
    "token.fit_on_texts(x_train)\n",
    "x_train = token.texts_to_sequences(x_train)\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "\n",
    "max_length = get_max_length()\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
    "\n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6t84DuMu5TW"
   },
   "source": [
    "##### Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "S2n3umyVsDRZ",
    "outputId": "c71fbff6-d279-4f8e-ac3d-1c3bada7b238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 131, 32)           2963392   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                24832     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,992,449\n",
      "Trainable params: 2,992,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "EMBED_DIM = 32\n",
    "LSTM_OUT = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "model.add(LSTM(LSTM_OUT))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "jWHCQWXys3PL",
    "outputId": "46c5bc25-1ee0-40f5-e86e-6c4067d37136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 72s 209ms/step - loss: 0.4925 - accuracy: 0.7421\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 65s 208ms/step - loss: 0.2115 - accuracy: 0.9208\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 66s 210ms/step - loss: 0.1124 - accuracy: 0.9631\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 67s 214ms/step - loss: 0.0694 - accuracy: 0.9779\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 68s 218ms/step - loss: 0.0454 - accuracy: 0.9867\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 66s 211ms/step - loss: 0.0360 - accuracy: 0.9894\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 65s 209ms/step - loss: 0.0308 - accuracy: 0.9910\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 0.0263 - accuracy: 0.9922\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 0.0289 - accuracy: 0.9913\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 64s 205ms/step - loss: 0.0264 - accuracy: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2070253eb90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 128, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "szQCB945vjAS",
    "outputId": "0f0f65fd-04ec-4157-f03b-2da7d495add1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 13s 35ms/step - loss: 0.5002 - accuracy: 0.8607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.500201940536499, 0.8607000112533569]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kozbLa7Dxs1o"
   },
   "source": [
    "##### Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "6nsy8kSWuFpW",
    "outputId": "ece5add3-c1d0-45d8-d7ac-1611947adb34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 131, 32)           2963392   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,978,049\n",
      "Trainable params: 2,978,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ARCHITECTURE\n",
    "EMBED_DIM = 32\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "model1.add(LSTM(32))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "bKr2_XwJuNfk",
    "outputId": "33555784-b52a-40c0-b9ce-1fdc257048b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 56s 160ms/step - loss: 0.4760 - accuracy: 0.7312\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 50s 160ms/step - loss: 0.2044 - accuracy: 0.9246\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 0.1105 - accuracy: 0.9640\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 0.0707 - accuracy: 0.9779\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.0482 - accuracy: 0.9851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20701b889a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train, y_train, batch_size = 128, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52Aj3cXHxx34"
   },
   "source": [
    "##### Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "pooonVpkwUG6",
    "outputId": "737eb5de-383e-4d61-9ede-00e86d888927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 131, 32)           2963392   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              49664     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,021,377\n",
      "Trainable params: 3,021,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "EMBED_DIM = 32\n",
    "LSTM_OUT = 64\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "model2.add(Bidirectional(LSTM(LSTM_OUT)))\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "HwwFXnGnwjzg",
    "outputId": "d3c50663-b41e-4989-ef85-244dd8e0b0d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 109s 299ms/step - loss: 0.3998 - accuracy: 0.8094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20701b2f010>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, batch_size = 128)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
